{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Setup","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets peft torch sacrebleu --quiet","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:34:03.676616Z","iopub.execute_input":"2024-08-01T13:34:03.677348Z","iopub.status.idle":"2024-08-01T13:34:18.876554Z","shell.execute_reply.started":"2024-08-01T13:34:03.677318Z","shell.execute_reply":"2024-08-01T13:34:18.874917Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from transformers import MBartForConditionalGeneration, MBart50Tokenizer, AutoTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments\nfrom datasets import load_dataset, load_metric\nimport numpy as np\nimport torch, os","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:34:18.879080Z","iopub.execute_input":"2024-08-01T13:34:18.879521Z","iopub.status.idle":"2024-08-01T13:34:37.725011Z","shell.execute_reply.started":"2024-08-01T13:34:18.879481Z","shell.execute_reply":"2024-08-01T13:34:37.724229Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-01 13:34:25.787596: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-01 13:34:25.787704: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-01 13:34:25.933129: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:34:37.730297Z","iopub.execute_input":"2024-08-01T13:34:37.730606Z","iopub.status.idle":"2024-08-01T13:34:37.785078Z","shell.execute_reply.started":"2024-08-01T13:34:37.730581Z","shell.execute_reply":"2024-08-01T13:34:37.784095Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"raw_dataset = load_dataset('ai4bharat/samanantar', 'hi', split='train[:10000]', trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:34:37.786235Z","iopub.execute_input":"2024-08-01T13:34:37.786564Z","iopub.status.idle":"2024-08-01T13:50:53.859294Z","shell.execute_reply.started":"2024-08-01T13:34:37.786537Z","shell.execute_reply":"2024-08-01T13:50:53.858488Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/3.82k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1776c39bdefb44fcb926f3222d0e7a86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/6.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"872dc80ac15d43f3b3461d2456ce2c3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/7.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37aa7560218147b382e8ddc0a190cf9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecda75cf9086460c9911ab0a0da2f099"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = raw_dataset.take(10000)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:50:53.860483Z","iopub.execute_input":"2024-08-01T13:50:53.860750Z","iopub.status.idle":"2024-08-01T13:50:53.867954Z","shell.execute_reply.started":"2024-08-01T13:50:53.860727Z","shell.execute_reply":"2024-08-01T13:50:53.867085Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:50:53.868940Z","iopub.execute_input":"2024-08-01T13:50:53.869297Z","iopub.status.idle":"2024-08-01T13:50:53.880100Z","shell.execute_reply.started":"2024-08-01T13:50:53.869272Z","shell.execute_reply":"2024-08-01T13:50:53.879199Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['idx', 'src', 'tgt'],\n    num_rows: 10000\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Prepare the dataset for the model","metadata":{}},{"cell_type":"code","source":"tokenized_datasets = dataset.train_test_split(test_size=0.1)\ntrain_dataset = tokenized_datasets['train']\neval_dataset = tokenized_datasets['test']","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:50:53.881080Z","iopub.execute_input":"2024-08-01T13:50:53.881360Z","iopub.status.idle":"2024-08-01T13:50:53.909134Z","shell.execute_reply.started":"2024-08-01T13:50:53.881337Z","shell.execute_reply":"2024-08-01T13:50:53.908395Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_dataset[5]\neval_dataset[5]","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:50:53.910105Z","iopub.execute_input":"2024-08-01T13:50:53.910370Z","iopub.status.idle":"2024-08-01T13:50:53.920382Z","shell.execute_reply.started":"2024-08-01T13:50:53.910347Z","shell.execute_reply":"2024-08-01T13:50:53.919425Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'idx': 3419,\n 'src': 'Bigg Boss 14 contestant Rubina Dilaik is the winner of the season.',\n 'tgt': '‡§¨‡§ø‡§ó ‡§¨‡•â‡§∏ 14 ‡§∏‡•Ä‡§ú‡§® ‡§ï‡•á ‡§µ‡§ø‡§®‡§∞ ‡§ï‡§æ ‡§ñ‡§ø‡§§‡§æ‡§¨ ‡§∞‡•Å‡§¨‡•Ä‡§®‡§æ ‡§¶‡§ø‡§≤‡•à‡§ï ‡§®‡•á ‡§ú‡•Ä‡§§ ‡§≤‡§ø‡§Ø‡§æ ‡§π‡•à.'}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Load the Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\nmodel = MBartForConditionalGeneration.from_pretrained(model_name)\ntokenizer = MBart50Tokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:50:53.924502Z","iopub.execute_input":"2024-08-01T13:50:53.924917Z","iopub.status.idle":"2024-08-01T13:51:10.913501Z","shell.execute_reply.started":"2024-08-01T13:50:53.924878Z","shell.execute_reply":"2024-08-01T13:51:10.912324Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d66787342784b3b8e03663ff6feedef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7efc8d48043445dc912ca564c1e7f3fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1a6cd46342640e2969d1472732b0cd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9c4ca94f76e4afb82c555a853d8dc68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc166c7ccbae485a94abe723d96ccc0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6695d553b21f4cc8a8be77b90188cd8b"}},"metadata":{}}]},{"cell_type":"code","source":"#Define a function to tokenize the dataset\ndef preprocess_function(examples):\n    inputs = [ex for ex in examples['src']]\n    targets = [ex for ex in examples['tgt']]\n\n    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n\n    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\").input_ids\n\n    labels = [[-100 if token == tokenizer.pad_token_id else token for token in label] for label in labels]\n    \n    model_inputs[\"labels\"] = labels\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:51:10.915483Z","iopub.execute_input":"2024-08-01T13:51:10.915925Z","iopub.status.idle":"2024-08-01T13:51:10.927336Z","shell.execute_reply.started":"2024-08-01T13:51:10.915886Z","shell.execute_reply":"2024-08-01T13:51:10.923392Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\ntokenized_eval_dataset = eval_dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:51:10.930715Z","iopub.execute_input":"2024-08-01T13:51:10.931007Z","iopub.status.idle":"2024-08-01T13:51:24.972236Z","shell.execute_reply.started":"2024-08-01T13:51:10.930983Z","shell.execute_reply":"2024-08-01T13:51:24.971311Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e45e245aeb94ec39539593788240512"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df0fa0be650f4f4aa18bdfbb2c938b5a"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    weight_decay=0.01,\n    save_total_limit=1,\n    num_train_epochs=1,\n    predict_with_generate=True,\n    logging_dir='./logs',           # Directory for storing logs\n    logging_steps=10,               # Log every 10 steps\n    generation_max_length=128,      # Set maximum length for generation\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:51:24.973487Z","iopub.execute_input":"2024-08-01T13:51:24.973849Z","iopub.status.idle":"2024-08-01T13:51:25.105109Z","shell.execute_reply.started":"2024-08-01T13:51:24.973815Z","shell.execute_reply":"2024-08-01T13:51:25.104141Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"metric = load_metric(\"sacrebleu\")\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    \n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = metric.compute(predictions=decoded_preds, references=[[label] for label in decoded_labels])\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:51:25.106399Z","iopub.execute_input":"2024-08-01T13:51:25.106719Z","iopub.status.idle":"2024-08-01T13:52:11.738884Z","shell.execute_reply.started":"2024-08-01T13:51:25.106692Z","shell.execute_reply":"2024-08-01T13:52:11.737943Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1540555718.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric(\"sacrebleu\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e47990ebd1e343e9aab7f72803b65dde"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for sacrebleu contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/sacrebleu.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"}]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_eval_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:52:11.740322Z","iopub.execute_input":"2024-08-01T13:52:11.741641Z","iopub.status.idle":"2024-08-01T13:52:12.680657Z","shell.execute_reply.started":"2024-08-01T13:52:11.741602Z","shell.execute_reply":"2024-08-01T13:52:12.679523Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"save_directory = \"/kaggle/new_model/saved_model\"\n\nos.makedirs(save_directory, exist_ok=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:52:12.682300Z","iopub.execute_input":"2024-08-01T13:52:12.682704Z","iopub.status.idle":"2024-08-01T13:52:12.688102Z","shell.execute_reply.started":"2024-08-01T13:52:12.682668Z","shell.execute_reply":"2024-08-01T13:52:12.687159Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T13:52:12.689216Z","iopub.execute_input":"2024-08-01T13:52:12.689540Z","iopub.status.idle":"2024-08-01T14:15:50.350106Z","shell.execute_reply.started":"2024-08-01T13:52:12.689507Z","shell.execute_reply":"2024-08-01T14:15:50.349238Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='563' max='563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [563/563 23:33, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Score</th>\n      <th>Counts</th>\n      <th>Totals</th>\n      <th>Precisions</th>\n      <th>Bp</th>\n      <th>Sys Len</th>\n      <th>Ref Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.059300</td>\n      <td>2.027637</td>\n      <td>18.694625</td>\n      <td>[9233, 4478, 2409, 1341]</td>\n      <td>[18784, 17784, 16785, 15792]</td>\n      <td>[49.15353492333901, 25.179937022042285, 14.352100089365505, 8.49164133738602]</td>\n      <td>0.948610</td>\n      <td>18784</td>\n      <td>19775</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5, 'forced_eos_token_id': 2}\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nTrainer is attempting to log a value of \"[9233, 4478, 2409, 1341]\" of type <class 'list'> for key \"eval/counts\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"[18784, 17784, 16785, 15792]\" of type <class 'list'> for key \"eval/totals\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"[49.15353492333901, 25.179937022042285, 14.352100089365505, 8.49164133738602]\" of type <class 'list'> for key \"eval/precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=563, training_loss=2.2042956157433626, metrics={'train_runtime': 1416.5948, 'train_samples_per_second': 6.353, 'train_steps_per_second': 0.397, 'total_flos': 2438020988928000.0, 'train_loss': 2.2042956157433626, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Save the Finetuned Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"# save the trained model\ntrainer.save_model('/.finetuned-MBart-en-ta')\n# save model and tokenizer \nmodel.save_pretrained(save_directory)\ntokenizer.save_pretrained(save_directory)\n\nprint(f\"Model saved to {save_directory}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:22:17.534362Z","iopub.execute_input":"2024-08-01T14:22:17.535008Z","iopub.status.idle":"2024-08-01T14:22:41.048857Z","shell.execute_reply.started":"2024-08-01T14:22:17.534976Z","shell.execute_reply":"2024-08-01T14:22:41.047805Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 200, 'early_stopping': True, 'num_beams': 5, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"name":"stdout","text":"Model saved to /kaggle/new_model/saved_model\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load the Finetuned model and check out the translation","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nimport torch\n\n#Load your model  and tokenizer\nmodel_name = save_directory\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n#Example English sentence to translate\nenglish_sentence = \"I think this project will go really well\"\n\n#Tokenize the input sentence\ninputs = tokenizer(english_sentence, return_tensors =\"pt\").to(device)\n\n#Generate the transaltion\nwith torch.no_grad():\n    outputs = model.generate(**inputs, max_length = 128, num_beams = 4, early_stopping = True)\n    \n#Decode the generated tokens\ntranslated_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(f\"English: {english_sentence}\")\nprint(f\"Hindi Translation: {translated_sentence}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T14:23:07.792891Z","iopub.execute_input":"2024-08-01T14:23:07.793600Z","iopub.status.idle":"2024-08-01T14:23:16.636312Z","shell.execute_reply.started":"2024-08-01T14:23:07.793567Z","shell.execute_reply":"2024-08-01T14:23:16.635380Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"English: I think this project will go really well\nHindi Translation: ‡§Æ‡•Å‡§ù‡•á ‡§≤‡§ó‡§§‡§æ ‡§π‡•à ‡§ï‡§ø ‡§Ø‡§π ‡§™‡§∞‡§ø‡§Ø‡•ã‡§ú‡§®‡§æ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§ö‡§≤‡•á‡§ó‡•Ä\n","output_type":"stream"}]}]}