{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9069992,"sourceType":"datasetVersion","datasetId":5470778},{"sourceId":9071679,"sourceType":"datasetVersion","datasetId":5471916}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"!pip install datasets transformers torch accelerate sacremoses sacrebleu --quiet\n!pip install dataset --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-31T13:52:52.018814Z","iopub.execute_input":"2024-07-31T13:52:52.019543Z","iopub.status.idle":"2024-07-31T13:53:21.620628Z","shell.execute_reply.started":"2024-07-31T13:52:52.019503Z","shell.execute_reply":"2024-07-31T13:53:21.619314Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.53 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch, os\nfrom transformers import MarianTokenizer, MarianMTModel\nimport pandas as pd\nimport sacrebleu\nfrom tqdm import tqdm\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-31T13:53:21.622828Z","iopub.execute_input":"2024-07-31T13:53:21.623195Z","iopub.status.idle":"2024-07-31T13:53:26.970369Z","shell.execute_reply.started":"2024-07-31T13:53:21.623162Z","shell.execute_reply":"2024-07-31T13:53:26.969304Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-07-31T13:53:26.971706Z","iopub.execute_input":"2024-07-31T13:53:26.972289Z","iopub.status.idle":"2024-07-31T13:53:26.979313Z","shell.execute_reply.started":"2024-07-31T13:53:26.972258Z","shell.execute_reply":"2024-07-31T13:53:26.978123Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Load the Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"model_name = '/kaggle/input/finetuned-opusmt-en-hi-ta-model'\ntokenizer = MarianTokenizer.from_pretrained(model_name)\n# Load the model\nmodel = MarianMTModel.from_pretrained(model_name)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T13:53:26.981532Z","iopub.execute_input":"2024-07-31T13:53:26.981918Z","iopub.status.idle":"2024-07-31T13:53:31.722230Z","shell.execute_reply.started":"2024-07-31T13:53:26.981888Z","shell.execute_reply":"2024-07-31T13:53:31.721068Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"MarianMTModel(\n  (model): MarianModel(\n    (shared): Embedding(64110, 512, padding_idx=64109)\n    (encoder): MarianEncoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLU()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (decoder): MarianDecoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLU()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=64110, bias=False)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tatoeba Benchmark Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Load Tatoeba dataset","metadata":{}},{"cell_type":"code","source":"# Load the dataset \ndf = pd.read_csv('/kaggle/input/tatoeba-gujarati/Tatoeba-gujarati.csv')\nenglish_sentences = df['English'].tolist()\ngujarati_sentences = df['Gujarati'].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-07-31T13:53:31.723660Z","iopub.execute_input":"2024-07-31T13:53:31.724088Z","iopub.status.idle":"2024-07-31T13:53:31.748190Z","shell.execute_reply.started":"2024-07-31T13:53:31.724058Z","shell.execute_reply":"2024-07-31T13:53:31.747179Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(english_sentences[:10])\nprint(gujarati_sentences[:10])","metadata":{"execution":{"iopub.status.busy":"2024-07-31T13:53:31.749398Z","iopub.execute_input":"2024-07-31T13:53:31.749702Z","iopub.status.idle":"2024-07-31T13:53:31.755203Z","shell.execute_reply.started":"2024-07-31T13:53:31.749677Z","shell.execute_reply":"2024-07-31T13:53:31.754286Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['Ahmedabad is the largest city in Gujarat.', 'Ajay is a bad boy.', 'Ajay is bad.', 'Ajay is poor.', 'Algeria is a country in North Africa.', 'A nephew is the son of a sibling.', 'A niece is the daughter of a brother.', 'A niece is the daughter of a sibling.', 'A niece is the daughter of a sister.', 'Are you alone?']\n['અમદાવાદ ગુજરાતનું સૌથી મોટુ શહેર છે.', 'અજય ગરીબ છે.', 'અજય ગરીબ છે.', 'અજય ગરીબ છે.', 'ઉત્તર આફ્રિકામાં અલજીર્યા એક દેશ છે.', 'ભાઈ કે બહેનના દીકરાને ભત્રીજો કહેવાય', 'ભાઈની પુત્રી ને ભત્રીજી ક્હેવાય', 'ભાઈ કે બહેનની પુત્રી ને ભત્રીજી ક્હેવાય', 'બહેનની પુત્રી ને ભાણેજ ક્હેવાય', 'તું એકલો છો?']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Calculate BLEU: Tatoeba","metadata":{}},{"cell_type":"code","source":"# Function to generate translation for a given input text\ndef generate_translation(input_text):\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n    with torch.no_grad():\n        output_ids = model.generate(input_ids)\n    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return output_text\n\ntranslations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append([gujarati_sentences[i]])\n\n# Calculate BLEU score\nbleu = sacrebleu.corpus_bleu(translations, references)\nprint(f\"BLEU score: {bleu.score}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-31T13:53:31.756548Z","iopub.execute_input":"2024-07-31T13:53:31.756884Z","iopub.status.idle":"2024-07-31T13:54:55.853144Z","shell.execute_reply.started":"2024-07-31T13:53:31.756857Z","shell.execute_reply":"2024-07-31T13:54:55.852044Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 154/154 [01:24<00:00,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"BLEU score: 26.269098944241588\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# IN-22 Benchmark Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Load IN-22 dataset","metadata":{}},{"cell_type":"code","source":"# download and load specific pairs\ndataset = load_dataset(\"ai4bharat/IN22-Gen\", \"eng_Latn-guj_Gujr\", trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T13:54:55.854444Z","iopub.execute_input":"2024-07-31T13:54:55.854932Z","iopub.status.idle":"2024-07-31T13:55:01.751656Z","shell.execute_reply.started":"2024-07-31T13:54:55.854904Z","shell.execute_reply":"2024-07-31T13:55:01.750675Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8815cd07bb264892913d01d1039a51a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18f775c05a0e4307a5118f442e0587cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b647dca950b44e498055189acc12f3c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating gen split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c85ec05029345b3ac764552aefc9227"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-31T13:55:01.752836Z","iopub.execute_input":"2024-07-31T13:55:01.753169Z","iopub.status.idle":"2024-07-31T13:55:01.759361Z","shell.execute_reply.started":"2024-07-31T13:55:01.753142Z","shell.execute_reply":"2024-07-31T13:55:01.758449Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    gen: Dataset({\n        features: ['id', 'context', 'source', 'url', 'domain', 'num_words', 'bucket', 'sentence_eng_Latn', 'sentence_guj_Gujr'],\n        num_rows: 1024\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"english_sentences = dataset['gen']['sentence_eng_Latn']\ngujarati_sentences = dataset['gen']['sentence_guj_Gujr']\n\n# Convert them to lists\nenglish_sentences = list(english_sentences)\ngujarati_sentences = list(gujarati_sentences)\n\n# Verify the first few elements of each list\nprint(english_sentences[:5])\nprint(gujarati_sentences[:5])","metadata":{"execution":{"iopub.status.busy":"2024-07-31T13:55:01.762374Z","iopub.execute_input":"2024-07-31T13:55:01.762714Z","iopub.status.idle":"2024-07-31T13:55:01.776115Z","shell.execute_reply.started":"2024-07-31T13:55:01.762681Z","shell.execute_reply":"2024-07-31T13:55:01.775126Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['An appearance is a bunch of attributes related to the service person, like their shoes, clothes, tie, jewellery, hairstyle, make-up, watch, cosmetics, perfume, etc.', 'Ajanta, located in the Aurangabad District of Maharashtra has twenty-nine caitya and vihara caves decorated with sculptures and paintings from the first century B.C.E. to the fifth century C.E.', 'Body colour gets merged with the outer line, creating the effect of volume.', 'Ashoka started making extensive use of stone for sculptures and great monuments, whereas the previous tradition consisted of working with wood and clay.', 'Potatoes mixed in masalas, coated in besan batter and deep fried to perfection form this delicious and famous dish of Maharashtra.']\n['દેખાવ એ સેવા કર્મીના લક્ષણોનો સમૂહ છે, જેમ કે તેમના બૂટ, કપડાં, ટાઈ, આભૂષણો, કેશકલાપ. શણગાર, ઘડિયાળ, શૃંગાર દ્રવ્યો, અત્તર, વગેરે.', 'મહારાષ્ટ્રના ઔરંગાબાદ જીલ્લામાં સ્થિત અજંતામાં ઓગણત્રીસ કૈત્ય અને વિહાર ગુફાઓ છે, જે ઈ.સ.પૂ. પ્રથમ સદીથી ઈ.સ. પાંચમી સદી સુધીના શિલ્પો અને ચિત્રોથી સુશોભિત છે.', 'શરીરનો રંગ બાહ્ય રેખા સાથે ભળીને ઘનતાની અસર સર્જે છે.', 'અશોકે શિલ્પો અને વિરાટ સ્મારકો બનાવવા માટે પથ્થરોનો વિસ્તૃત ઉપયોગ શરુ કર્યો, જયારે અગાઉની પરંપરા લાકડા અને માટીના કામ સાથે બનેલી હતી.', 'બેસનમાં રગદોળાયેલા અને શ્રેષ્ઠ રીતે તળાયેલા મસાલા મિશ્રિત બટેટા મહારાષ્ટ્રની સ્વાદિષ્ટ અને પ્રખ્યાત વાનગી બને છે.']\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import MarianTokenizer, MarianMTModel\n\nmodel_name = '/kaggle/input/finetuned-opusmt-en-hi-ta-model'\ntokenizer = MarianTokenizer.from_pretrained(model_name)\n# Load the model\nmodel = MarianMTModel.from_pretrained(model_name)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T13:55:01.777342Z","iopub.execute_input":"2024-07-31T13:55:01.777761Z","iopub.status.idle":"2024-07-31T13:55:03.258982Z","shell.execute_reply.started":"2024-07-31T13:55:01.777724Z","shell.execute_reply":"2024-07-31T13:55:03.257884Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"MarianMTModel(\n  (model): MarianModel(\n    (shared): Embedding(64110, 512, padding_idx=64109)\n    (encoder): MarianEncoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLU()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (decoder): MarianDecoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLU()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=64110, bias=False)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Calculate BLEU: IN-22","metadata":{}},{"cell_type":"code","source":"# Function to generate translation for a given input text\ndef generate_translation(input_text):\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n    with torch.no_grad():\n        output_ids = model.generate(input_ids)\n    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return output_text\n\ntranslations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append([gujarati_sentences[i]])\n\n# Calculate BLEU score\nbleu = sacrebleu.corpus_bleu(translations, references)\nprint(f\"BLEU score: {bleu.score}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-31T13:55:03.260154Z","iopub.execute_input":"2024-07-31T13:55:03.260472Z","iopub.status.idle":"2024-07-31T14:40:19.186733Z","shell.execute_reply.started":"2024-07-31T13:55:03.260447Z","shell.execute_reply":"2024-07-31T14:40:19.185496Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 1024/1024 [45:15<00:00,  2.65s/it]\n","output_type":"stream"},{"name":"stdout","text":"BLEU score: 5.811055908327921\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Calculate chrF","metadata":{}},{"cell_type":"code","source":"translations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append(gujarati_sentences[i])  \n# Calculate chrF score\nchrf = sacrebleu.corpus_chrf(translations, references)\nprint(f\"chrF score: {chrf.score}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-31T14:40:19.188271Z","iopub.execute_input":"2024-07-31T14:40:19.188613Z","iopub.status.idle":"2024-07-31T15:25:28.371822Z","shell.execute_reply.started":"2024-07-31T14:40:19.188584Z","shell.execute_reply":"2024-07-31T15:25:28.370704Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 1024/1024 [45:07<00:00,  2.64s/it]\n","output_type":"stream"},{"name":"stdout","text":"chrF score: 5.447470817120622\n","output_type":"stream"}]}]}