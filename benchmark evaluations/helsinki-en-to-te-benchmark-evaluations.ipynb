{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9068137,"sourceType":"datasetVersion","datasetId":5469398},{"sourceId":9068141,"sourceType":"datasetVersion","datasetId":5469402}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"!pip install datasets transformers torch accelerate sacremoses sacrebleu --quiet\n!pip install dataset --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-30T15:33:32.877964Z","iopub.execute_input":"2024-07-30T15:33:32.878529Z","iopub.status.idle":"2024-07-30T15:34:09.850877Z","shell.execute_reply.started":"2024-07-30T15:33:32.878492Z","shell.execute_reply":"2024-07-30T15:34:09.849421Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.53 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch, os\nfrom transformers import MarianTokenizer, MarianMTModel\nimport pandas as pd\nimport sacrebleu\nfrom tqdm import tqdm\nfrom datasets import load_dataset\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T15:34:09.853357Z","iopub.execute_input":"2024-07-30T15:34:09.853723Z","iopub.status.idle":"2024-07-30T15:34:16.282043Z","shell.execute_reply.started":"2024-07-30T15:34:09.853686Z","shell.execute_reply":"2024-07-30T15:34:16.280884Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-07-30T15:34:16.287948Z","iopub.execute_input":"2024-07-30T15:34:16.288334Z","iopub.status.idle":"2024-07-30T15:34:16.295749Z","shell.execute_reply.started":"2024-07-30T15:34:16.288301Z","shell.execute_reply":"2024-07-30T15:34:16.294582Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Load the Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"model_name = '/kaggle/input/finetuned-opusmt-en-to-te-model'\ntokenizer = MarianTokenizer.from_pretrained(model_name)\n# Load the model\nmodel = MarianMTModel.from_pretrained(model_name)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T15:34:16.297373Z","iopub.execute_input":"2024-07-30T15:34:16.297864Z","iopub.status.idle":"2024-07-30T15:34:22.743472Z","shell.execute_reply.started":"2024-07-30T15:34:16.297822Z","shell.execute_reply":"2024-07-30T15:34:22.741964Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"MarianMTModel(\n  (model): MarianModel(\n    (shared): Embedding(64110, 512, padding_idx=64109)\n    (encoder): MarianEncoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLU()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (decoder): MarianDecoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLU()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=64110, bias=False)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tatoeba Benchmark Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Load Tatoeba dataset","metadata":{}},{"cell_type":"code","source":"# Load the dataset \ndf = pd.read_csv('/kaggle/input/tatoeba-telugu/Tatoeba-telugu.csv')\nenglish_sentences = df['English'].tolist()\ntelugu_sentences = df['Telugu'].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-07-30T15:34:22.744991Z","iopub.execute_input":"2024-07-30T15:34:22.745404Z","iopub.status.idle":"2024-07-30T15:34:22.768744Z","shell.execute_reply.started":"2024-07-30T15:34:22.745372Z","shell.execute_reply":"2024-07-30T15:34:22.767524Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(english_sentences[:10])\nprint(telugu_sentences[:10])","metadata":{"execution":{"iopub.status.busy":"2024-07-30T15:34:22.770243Z","iopub.execute_input":"2024-07-30T15:34:22.770647Z","iopub.status.idle":"2024-07-30T15:34:22.776553Z","shell.execute_reply.started":"2024-07-30T15:34:22.770616Z","shell.execute_reply":"2024-07-30T15:34:22.775304Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['A cat came out from under the desk.', 'Ah! How beautiful the Taj Mahal is!', 'Ah! How serene is this temple!', 'Are you feeling OK?', 'Are you for real?!', 'Are you guys doing well?', 'Are you guys OK?', 'Are you mad?', 'Are you prepared to do this?', 'Are you still afraid something might happen?']\n['ఒక పిల్లి డెస్క్ కింద నుండి బయటకు వచ్చింది.', 'ఆహా! తాజ్ మహల్ ఎంత బాగుంది!', 'ఆహా! ఈ గుడి ఎంత ప్రశాంతంగా ఉంది!', 'వొంట్లో ఎలా వుంది', 'ఎమిటీ! ఇది నిజమా?', 'మీరు బాగున్నారా ?', 'మీరు బాగున్నారా ?', 'కోపమొచ్చిందా ?', 'ఇది చెయ్యడానికి సిద్దంగా వున్నావా', 'ఏమైనా అవుతుందని ఇంకా భయపడుతున్నావా ?']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Calculate BLEU: Tatoeba","metadata":{}},{"cell_type":"code","source":"# Function to generate translation for a given input text\ndef generate_translation(input_text):\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n    with torch.no_grad():\n        output_ids = model.generate(input_ids)\n    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return output_text\n\ntranslations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append([telugu_sentences[i]])\n\n# Calculate BLEU score\nbleu = sacrebleu.corpus_bleu(translations, references)\nprint(f\"BLEU score: {bleu.score}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T15:34:22.778011Z","iopub.execute_input":"2024-07-30T15:34:22.778420Z","iopub.status.idle":"2024-07-30T15:36:52.607028Z","shell.execute_reply.started":"2024-07-30T15:34:22.778363Z","shell.execute_reply":"2024-07-30T15:36:52.605708Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 262/262 [02:29<00:00,  1.75it/s]","output_type":"stream"},{"name":"stdout","text":"BLEU score: 24.446151121745064\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# IN-22 Benchmark Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Load IN-22 dataset","metadata":{}},{"cell_type":"code","source":"# download and load specific pairs\ndataset = load_dataset(\"ai4bharat/IN22-Gen\", \"eng_Latn-tel_Telu\", trust_remote_code=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T15:36:52.608566Z","iopub.execute_input":"2024-07-30T15:36:52.609157Z","iopub.status.idle":"2024-07-30T15:36:58.710533Z","shell.execute_reply.started":"2024-07-30T15:36:52.609120Z","shell.execute_reply":"2024-07-30T15:36:58.709190Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc00187219214685a9871a280bf85bcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8d7e9a2bce148a7ba3f53d026df9971"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e33a70338054f4693b51fc229fa51a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating gen split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adb1eb188db04e269ed4d26552abc7e1"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-30T15:36:58.713686Z","iopub.execute_input":"2024-07-30T15:36:58.714083Z","iopub.status.idle":"2024-07-30T15:36:58.722455Z","shell.execute_reply.started":"2024-07-30T15:36:58.714047Z","shell.execute_reply":"2024-07-30T15:36:58.721171Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    gen: Dataset({\n        features: ['id', 'context', 'source', 'url', 'domain', 'num_words', 'bucket', 'sentence_eng_Latn', 'sentence_tel_Telu'],\n        num_rows: 1024\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"english_sentences = dataset['gen']['sentence_eng_Latn']\ntelugu_sentences = dataset['gen']['sentence_tel_Telu']\n\n# Convert them to lists\nenglish_sentences = list(english_sentences)\ntelugu_sentences = list(telugu_sentences)\n\n# Verify the first few elements of each list\nprint(english_sentences[:5])\nprint(telugu_sentences[:5])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T15:36:58.723872Z","iopub.execute_input":"2024-07-30T15:36:58.724248Z","iopub.status.idle":"2024-07-30T15:36:58.745361Z","shell.execute_reply.started":"2024-07-30T15:36:58.724208Z","shell.execute_reply":"2024-07-30T15:36:58.744189Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['An appearance is a bunch of attributes related to the service person, like their shoes, clothes, tie, jewellery, hairstyle, make-up, watch, cosmetics, perfume, etc.', 'Ajanta, located in the Aurangabad District of Maharashtra has twenty-nine caitya and vihara caves decorated with sculptures and paintings from the first century B.C.E. to the fifth century C.E.', 'Body colour gets merged with the outer line, creating the effect of volume.', 'Ashoka started making extensive use of stone for sculptures and great monuments, whereas the previous tradition consisted of working with wood and clay.', 'Potatoes mixed in masalas, coated in besan batter and deep fried to perfection form this delicious and famous dish of Maharashtra.']\n['బాహ్య రూపం అనేది సేవ చేసే వ్యక్తి తాలూకు బూట్లు, బట్టలు, టై, ఆభరణాలు, కేశాలంకరణ, అలంకరణ, గడియారం, సౌందర్య సాధనాలు,అత్తరు మొదలైనటువంటి వాటికి సంబంధించిన లక్షణాల సమాహారం.', 'మహారాష్ట్ర లోని ఔరంగాబాద్ జిల్లాలో నెలకొని ఉన్నఅజంతా, ఇరవై తొమ్మిది చైత్యా మరియు విహారా గుహలు కలిగి ఉంది, ఇవి క్రీ పూ ఒకటవ శతాబ్దం- క్రీ శ ఐదవ శతబ్దం మధ్య కాలపు శిల్పాలు మరియు చిత్రాలతో అలంకరించబడి ఉంటాయి.', 'శరీరపు రంగు ఆవరణరేఖతో కలిసిపోయి, ఘనపరిమాణ భావం కలిగిస్తుంది.', 'అశోకుడు శిల్పాలు, గొప్ప కట్టడాల కోసం రాతిని విస్తృతంగా ఉపయోగించడం మొదలుపెట్టాడు, కాగా అంతకు మునుపటి సంప్రదాయంలో చెక్క మరియు బంకమట్టిని ఉపయోగించేవారు.', 'మహారాష్ట్రకు చెందిన ఈ రుచికరమైన, ప్రసిద్ధ వంటకాన్ని తయారు చేయడానికి బంగాళాదుంపలను మసాలాలతో కలిపి, శనగపిండిలో ముంచి నూనెలో బాగా వేయిస్తారు.']\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import MarianTokenizer, MarianMTModel\n\nmodel_name = '/kaggle/input/finetuned-opusmt-en-to-te-model'\ntokenizer = MarianTokenizer.from_pretrained(model_name)\n# Load the model\nmodel = MarianMTModel.from_pretrained(model_name)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T15:36:58.746908Z","iopub.execute_input":"2024-07-30T15:36:58.747416Z","iopub.status.idle":"2024-07-30T15:37:01.184095Z","shell.execute_reply.started":"2024-07-30T15:36:58.747380Z","shell.execute_reply":"2024-07-30T15:37:01.182854Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"MarianMTModel(\n  (model): MarianModel(\n    (shared): Embedding(64110, 512, padding_idx=64109)\n    (encoder): MarianEncoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLU()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (decoder): MarianDecoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLU()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=64110, bias=False)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Calculate BLEU: IN-22","metadata":{}},{"cell_type":"code","source":"# Function to generate translation for a given input text\ndef generate_translation(input_text):\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n    with torch.no_grad():\n        output_ids = model.generate(input_ids)\n    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return output_text\n\ntranslations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append([telugu_sentences[i]])\n\n# Calculate BLEU score\nbleu = sacrebleu.corpus_bleu(translations, references)\nprint(f\"BLEU score: {bleu.score}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T15:37:01.185754Z","iopub.execute_input":"2024-07-30T15:37:01.186218Z","iopub.status.idle":"2024-07-30T16:20:22.149090Z","shell.execute_reply.started":"2024-07-30T15:37:01.186177Z","shell.execute_reply":"2024-07-30T16:20:22.147342Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 1024/1024 [43:20<00:00,  2.54s/it]\n","output_type":"stream"},{"name":"stdout","text":"BLEU score: 10.640850690356462\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Calculate chrF","metadata":{}},{"cell_type":"code","source":"translations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append(telugu_sentences[i])  \n# Calculate chrF score\nchrf = sacrebleu.corpus_chrf(translations, references)\nprint(f\"chrF score: {chrf.score}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T16:20:22.151292Z","iopub.execute_input":"2024-07-30T16:20:22.151737Z","iopub.status.idle":"2024-07-30T17:02:36.294665Z","shell.execute_reply.started":"2024-07-30T16:20:22.151695Z","shell.execute_reply":"2024-07-30T17:02:36.293523Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 1024/1024 [42:12<00:00,  2.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"chrF score: 5.3475935828877015\n","output_type":"stream"}]}]}