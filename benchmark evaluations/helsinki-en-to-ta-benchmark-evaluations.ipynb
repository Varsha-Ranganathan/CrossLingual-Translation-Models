{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9063639,"sourceType":"datasetVersion","datasetId":5466017},{"sourceId":9063644,"sourceType":"datasetVersion","datasetId":5466020}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"!pip install datasets transformers torch accelerate sacremoses sacrebleu --quiet\n!pip install dataset --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-30T13:58:56.328311Z","iopub.execute_input":"2024-07-30T13:58:56.328643Z","iopub.status.idle":"2024-07-30T13:59:21.130358Z","shell.execute_reply.started":"2024-07-30T13:58:56.328611Z","shell.execute_reply":"2024-07-30T13:59:21.128728Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch, os\nfrom transformers import MarianTokenizer, MarianMTModel\nimport pandas as pd\nimport sacrebleu\nfrom tqdm import tqdm\nfrom datasets import load_dataset\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T13:59:21.137373Z","iopub.execute_input":"2024-07-30T13:59:21.137698Z","iopub.status.idle":"2024-07-30T13:59:24.530433Z","shell.execute_reply.started":"2024-07-30T13:59:21.137667Z","shell.execute_reply":"2024-07-30T13:59:24.529356Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-07-30T13:59:24.531802Z","iopub.execute_input":"2024-07-30T13:59:24.532401Z","iopub.status.idle":"2024-07-30T13:59:24.540664Z","shell.execute_reply.started":"2024-07-30T13:59:24.532369Z","shell.execute_reply":"2024-07-30T13:59:24.539542Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Load the Model and Tokenizer","metadata":{}},{"cell_type":"code","source":"model_name = '/kaggle/input/finetuned-opusmt-en-to-ta-model'\ntokenizer = MarianTokenizer.from_pretrained(model_name)\n# Load the model\nmodel = MarianMTModel.from_pretrained(model_name)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T13:59:24.543460Z","iopub.execute_input":"2024-07-30T13:59:24.543800Z","iopub.status.idle":"2024-07-30T13:59:26.678017Z","shell.execute_reply.started":"2024-07-30T13:59:24.543769Z","shell.execute_reply":"2024-07-30T13:59:26.676351Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"MarianMTModel(\n  (model): MarianModel(\n    (shared): Embedding(64110, 512, padding_idx=64109)\n    (encoder): MarianEncoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLU()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (decoder): MarianDecoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLU()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=64110, bias=False)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tatoeba Benchmark Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Load Tatoeba dataset","metadata":{}},{"cell_type":"code","source":"# Load the dataset \ndf = pd.read_csv('/kaggle/input/tatoeba-tamil/Tatoeba-tamil.csv')\nenglish_sentences = df['English'].tolist()\ntamil_sentences = df['Tamil'].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-07-30T13:59:26.679795Z","iopub.execute_input":"2024-07-30T13:59:26.680373Z","iopub.status.idle":"2024-07-30T13:59:26.696432Z","shell.execute_reply.started":"2024-07-30T13:59:26.680335Z","shell.execute_reply":"2024-07-30T13:59:26.694353Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(english_sentences[:10])\nprint(tamil_sentences[:10])","metadata":{"execution":{"iopub.status.busy":"2024-07-30T13:59:26.698899Z","iopub.execute_input":"2024-07-30T13:59:26.699368Z","iopub.status.idle":"2024-07-30T13:59:26.706453Z","shell.execute_reply.started":"2024-07-30T13:59:26.699316Z","shell.execute_reply":"2024-07-30T13:59:26.705339Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['All of them went there.', 'All of us were silent.', 'Are you ready to go?', 'As all letters have the letter A for their first, so the world has the eternal God for its first.', 'A square has four equal sides.', 'A square has four sides.', \"Because he's sick, he can't come.\", 'Be kind to old people.', 'Beware of pickpockets.', 'Beware of the dog!']\n['அவர்கள் எல்லோரும் அங்கே சென்றார்கள்', 'நாங்கள் அனைவரும் அமைதியாக இருந்தோம்', 'நீங்கள் போகத் தயாராக இருக்கிறீர்களா?', 'அகர முதல எழுத்தெல்லாம் ஆதி பகவன் முதற்றே உலகு.', 'ஒரு சதுரத்திற்கு நான்கு சமமான பக்கங்கள் உள்ளன', 'ஒரு சதுரத்திற்கு நான்கு பக்கங்கள் உள்ளன', 'அவனுக்கு உடல் நிலை சரியில்லாததனால் அவனால் வர இயலாது', 'வயோதிகர்களிடம் அன்பாக இரு', 'ஜேப்படிகாரர்களிடம் ஜாக்கிரதையாக இருக்கவும்', 'நாய் ஜாக்கிரதை!']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Calculate BLEU: Tatoeba","metadata":{}},{"cell_type":"code","source":"# Function to generate translation for a given input text\ndef generate_translation(input_text):\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n    with torch.no_grad():\n        output_ids = model.generate(input_ids)\n    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return output_text\n\ntranslations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append([tamil_sentences[i]])\n\n# Calculate BLEU score\nbleu = sacrebleu.corpus_bleu(translations, references)\nprint(f\"BLEU score: {bleu.score}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T13:59:26.708809Z","iopub.execute_input":"2024-07-30T13:59:26.710274Z","iopub.status.idle":"2024-07-30T14:02:37.390985Z","shell.execute_reply.started":"2024-07-30T13:59:26.710219Z","shell.execute_reply":"2024-07-30T14:02:37.389813Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 356/356 [03:10<00:00,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"BLEU score: 14.058533129758727\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# IN-22 Benchmark Evaluation","metadata":{}},{"cell_type":"markdown","source":"## Load IN-22 dataset","metadata":{}},{"cell_type":"code","source":"# download and load specific pairs\ndataset = load_dataset(\"ai4bharat/IN22-Gen\", \"eng_Latn-tam_Taml\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T14:02:37.392530Z","iopub.execute_input":"2024-07-30T14:02:37.393085Z","iopub.status.idle":"2024-07-30T14:03:18.565530Z","shell.execute_reply.started":"2024-07-30T14:02:37.393047Z","shell.execute_reply":"2024-07-30T14:03:18.564282Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdin","text":"The repository for ai4bharat/IN22-Gen contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ai4bharat/IN22-Gen.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b6939775e31402b92f5de734ea6166c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating gen split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb51003df9e24d98a103d84a6a350bc0"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-30T14:03:18.567102Z","iopub.execute_input":"2024-07-30T14:03:18.567477Z","iopub.status.idle":"2024-07-30T14:03:18.575661Z","shell.execute_reply.started":"2024-07-30T14:03:18.567444Z","shell.execute_reply":"2024-07-30T14:03:18.574564Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    gen: Dataset({\n        features: ['id', 'context', 'source', 'url', 'domain', 'num_words', 'bucket', 'sentence_eng_Latn', 'sentence_tam_Taml'],\n        num_rows: 1024\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"english_sentences = dataset['gen']['sentence_eng_Latn']\ntamil_sentences = dataset['gen']['sentence_tam_Taml']\n\n# Convert them to lists\nenglish_sentences = list(english_sentences)\ntamil_sentences = list(tamil_sentences)\n\n# Verify the first few elements of each list\nprint(english_sentences[:5])\nprint(tamil_sentences[:5])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T14:03:18.577418Z","iopub.execute_input":"2024-07-30T14:03:18.577844Z","iopub.status.idle":"2024-07-30T14:03:18.601772Z","shell.execute_reply.started":"2024-07-30T14:03:18.577804Z","shell.execute_reply":"2024-07-30T14:03:18.600573Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['An appearance is a bunch of attributes related to the service person, like their shoes, clothes, tie, jewellery, hairstyle, make-up, watch, cosmetics, perfume, etc.', 'Ajanta, located in the Aurangabad District of Maharashtra has twenty-nine caitya and vihara caves decorated with sculptures and paintings from the first century B.C.E. to the fifth century C.E.', 'Body colour gets merged with the outer line, creating the effect of volume.', 'Ashoka started making extensive use of stone for sculptures and great monuments, whereas the previous tradition consisted of working with wood and clay.', 'Potatoes mixed in masalas, coated in besan batter and deep fried to perfection form this delicious and famous dish of Maharashtra.']\n['தோற்றம் என்பது சேவை ஊழியரின் காலணிகள், உடை, டை, நகை, சிகையலங்காரம், மேக்-அப், கைக்கடிகாரம், அழகு சாதனங்கள், நறுமணம் போன்ற அவர் சார்ந்த பண்புகளின் ஒரு தொகுப்பைக் குறிக்கிறது.', 'மகாராஷ்டிரத்தின் அவுரங்காபாத் மாவட்டத்தில் உள்ள அஜந்தாவில் இருபத்தி ஒன்பது சைத்யா மற்றும் விஹாரா குகைகள் உள்ளன, அவற்றை கிமு முதலாம் நூற்றாண்டு முதல் கிபி ஐந்தாம் நூற்றாண்டு வரையிலான சிற்பங்களும் ஓவியங்களும் அலங்கரித்துள்ளன.', 'உடல் நிறம் ஓரங்களுடன் கலந்து பருமனான தோற்றத்தைத் தருகிறது.', 'சிற்பங்களுக்கும் மாபெரும் நினைவுச் சின்னங்களுக்கும் அசோகர் பெரியளவில் கற்களைப் பயன்படுத்தத் தொடங்கினார், ஆனால் அதற்கு முன்பு மரம் மற்றும் களிமண்ணைப் பயன்படுத்துவதே மரபாக இருந்தது.', 'மகாராஷ்டிராவின் இந்தப் புகழ்பெற்ற அறுசுவை உணவில், மசாலாக்களுடன் பிசைந்து கடலைமாவில் துவைத்து எண்ணெயில் பூரணமாகப் பொரித்த உருளைக்கிழங்குகள் உள்ளன.']\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import MarianTokenizer, MarianMTModel\n\nmodel_name = '/kaggle/input/finetuned-opusmt-en-to-ta-model'\ntokenizer = MarianTokenizer.from_pretrained(model_name)\n# Load the model\nmodel = MarianMTModel.from_pretrained(model_name)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-30T14:03:18.603150Z","iopub.execute_input":"2024-07-30T14:03:18.603552Z","iopub.status.idle":"2024-07-30T14:03:20.072428Z","shell.execute_reply.started":"2024-07-30T14:03:18.603522Z","shell.execute_reply":"2024-07-30T14:03:20.071055Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"MarianMTModel(\n  (model): MarianModel(\n    (shared): Embedding(64110, 512, padding_idx=64109)\n    (encoder): MarianEncoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianEncoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): SiLU()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n    (decoder): MarianDecoder(\n      (embed_tokens): Embedding(64110, 512, padding_idx=64109)\n      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n      (layers): ModuleList(\n        (0-5): 6 x MarianDecoderLayer(\n          (self_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): SiLU()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MarianAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=64110, bias=False)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Calculate BLEU: IN-22","metadata":{}},{"cell_type":"code","source":"# Function to generate translation for a given input text\ndef generate_translation(input_text):\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n    with torch.no_grad():\n        output_ids = model.generate(input_ids)\n    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return output_text\n\ntranslations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append([tamil_sentences[i]])\n\n# Calculate BLEU score\nbleu = sacrebleu.corpus_bleu(translations, references)\nprint(f\"BLEU score: {bleu.score}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-30T14:03:20.074224Z","iopub.execute_input":"2024-07-30T14:03:20.074676Z","iopub.status.idle":"2024-07-30T14:40:58.265159Z","shell.execute_reply.started":"2024-07-30T14:03:20.074636Z","shell.execute_reply":"2024-07-30T14:40:58.264048Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 1024/1024 [37:37<00:00,  2.21s/it]","output_type":"stream"},{"name":"stdout","text":"BLEU score: 5.8823705487151745\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Calculate chrF","metadata":{}},{"cell_type":"code","source":"translations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append(tamil_sentences[i])  \n# Calculate chrF score\nchrf = sacrebleu.corpus_chrf(translations, references)\nprint(f\"chrF score: {chrf.score}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-30T14:40:58.268425Z","iopub.execute_input":"2024-07-30T14:40:58.268779Z","iopub.status.idle":"2024-07-30T15:18:22.955491Z","shell.execute_reply.started":"2024-07-30T14:40:58.268749Z","shell.execute_reply":"2024-07-30T15:18:22.954149Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 1024/1024 [37:21<00:00,  2.19s/it]\n","output_type":"stream"},{"name":"stdout","text":"chrF score: 4.400440044004401\n","output_type":"stream"}]}]}