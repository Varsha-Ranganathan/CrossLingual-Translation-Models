{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9070826,"sourceType":"datasetVersion","datasetId":5471275},{"sourceId":9070833,"sourceType":"datasetVersion","datasetId":5471282}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets transformers torch accelerate sacremoses sacrebleu --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-31T03:33:05.750624Z","iopub.execute_input":"2024-07-31T03:33:05.750952Z","iopub.status.idle":"2024-07-31T03:33:19.773447Z","shell.execute_reply.started":"2024-07-31T03:33:05.750924Z","shell.execute_reply":"2024-07-31T03:33:19.772116Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch, os\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-07-31T03:33:19.774909Z","iopub.execute_input":"2024-07-31T03:33:19.775211Z","iopub.status.idle":"2024-07-31T03:33:21.715738Z","shell.execute_reply.started":"2024-07-31T03:33:19.775186Z","shell.execute_reply":"2024-07-31T03:33:21.714818Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from transformers import MBart50Tokenizer,MBartForConditionalGeneration\nmodel_name ='/kaggle/input/hindi-1-val'\ntokenizer = MBart50Tokenizer.from_pretrained(model_name)\n# Load the model\nmodel = MBartForConditionalGeneration.from_pretrained(model_name)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T03:33:21.717072Z","iopub.execute_input":"2024-07-31T03:33:21.717619Z","iopub.status.idle":"2024-07-31T03:33:30.659457Z","shell.execute_reply.started":"2024-07-31T03:33:21.717580Z","shell.execute_reply":"2024-07-31T03:33:30.658425Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"MBartForConditionalGeneration(\n  (model): MBartModel(\n    (shared): Embedding(250054, 1024, padding_idx=1)\n    (encoder): MBartEncoder(\n      (embed_tokens): MBartScaledWordEmbedding(250054, 1024, padding_idx=1)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x MBartEncoderLayer(\n          (self_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): ReLU()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): MBartDecoder(\n      (embed_tokens): MBartScaledWordEmbedding(250054, 1024, padding_idx=1)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x MBartDecoderLayer(\n          (self_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): ReLU()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=250054, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n# Load your dataset (assuming it's a CSV file with an 'english' column)\ndf = pd.read_csv('/kaggle/input/tatoeba-dataset/Tatoeba-Challenge.csv')\nenglish_sentences = df['English'].tolist()\nhindi_sentences = df['Hindi'].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-07-31T03:33:30.663422Z","iopub.execute_input":"2024-07-31T03:33:30.664053Z","iopub.status.idle":"2024-07-31T03:33:31.173242Z","shell.execute_reply.started":"2024-07-31T03:33:30.664011Z","shell.execute_reply":"2024-07-31T03:33:31.172091Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(english_sentences[:10])\nprint(hindi_sentences[:10])","metadata":{"execution":{"iopub.status.busy":"2024-07-31T03:33:31.174651Z","iopub.execute_input":"2024-07-31T03:33:31.175066Z","iopub.status.idle":"2024-07-31T03:33:31.181658Z","shell.execute_reply.started":"2024-07-31T03:33:31.175030Z","shell.execute_reply":"2024-07-31T03:33:31.180412Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[\"A baby is God's opinion that the world should go on.\", 'Absence of rain caused the plants to die.', 'A button has come off my raincoat.', 'A cat ran after a mouse.', 'A clock has two hands.', 'A country is a dangerous machine.', 'A crow is as black as coal.', 'Actinium was discovered by André-Louis Debierne in 1899.', 'Add a little sugar and cream.', 'Adopt the pace of nature: her secret is patience.']\n['नन्हे शिशु के जन्म का अर्थ है कि भगवान यह चाहते हैं कि यह दुनिया बनी रहे।', 'पौधे बारिश के बिना मर गए।', 'मेरे रेनकोट से एक बटन निकल आया है।', 'एक बिल्ली चूहे के पीछे भागी।', 'घड़ी के दो हाथ होते हैं.', 'देश एक खतरनाक मशीन होती है।', 'कौआ कोयले जैसा काला होता है।', 'ऐक्टिनियम का खोज आंड्रे-लूई डेबिएर्न ने साल १८९९ में किया था।', 'थोड़ी शक़्क़र और मलाई डालो।', 'प्रकृति की गति अपनाएं: उसका रहस्य है धीरज।']\n","output_type":"stream"}]},{"cell_type":"code","source":"import sacrebleu\nfrom tqdm import tqdm\n\n# Function to generate translation for a given input text\ndef generate_translation(input_text):\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n    with torch.no_grad():\n        output_ids = model.generate(input_ids)\n    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return output_text\n\n\ntranslations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append([hindi_sentences[i]])\n\n# Calculate BLEU score\nbleu = sacrebleu.corpus_bleu(translations, references)\nprint(f\"BLEU score: {bleu.score}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-31T03:33:31.182998Z","iopub.execute_input":"2024-07-31T03:33:31.183378Z","iopub.status.idle":"2024-07-31T03:56:49.960946Z","shell.execute_reply.started":"2024-07-31T03:33:31.183323Z","shell.execute_reply":"2024-07-31T03:56:49.959861Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 5000/5000 [23:18<00:00,  3.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"BLEU score: 11.208466750961147\n","output_type":"stream"}]},{"cell_type":"code","source":"translations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append(hindi_sentences[i])  # For chrF++, references should be a flat list\n\n# Calculate chrF++ score\nchrf = sacrebleu.corpus_chrf(translations, references)\nprint(f\"chrF++ score: {chrf.score}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-31T03:56:49.962202Z","iopub.execute_input":"2024-07-31T03:56:49.962715Z","iopub.status.idle":"2024-07-31T04:20:15.809812Z","shell.execute_reply.started":"2024-07-31T03:56:49.962685Z","shell.execute_reply":"2024-07-31T04:20:15.808765Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 5000/5000 [23:24<00:00,  3.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"chrF++ score: 14.563106796116504\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# download and load specific pairs\ndataset = load_dataset(\"ai4bharat/IN22-Gen\", \"eng_Latn-hin_Deva\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T04:20:15.811416Z","iopub.execute_input":"2024-07-31T04:20:15.811853Z","iopub.status.idle":"2024-07-31T04:20:27.258806Z","shell.execute_reply.started":"2024-07-31T04:20:15.811815Z","shell.execute_reply":"2024-07-31T04:20:27.257665Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d37051f3ec44ae289da378da4b3d266"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c883da8713c45e78a02479e87891c7a"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for ai4bharat/IN22-Gen contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ai4bharat/IN22-Gen.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d01f81101064e7fb5e38389001548ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating gen split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b093943393e448a4867c2a6683207631"}},"metadata":{}}]},{"cell_type":"code","source":"# Assuming 'sentence_eng_Latn' is the English column and 'sentence_hin_Deva' is the Hindi column\nenglish_sentences = dataset['gen']['sentence_eng_Latn']\nhindi_sentences = dataset['gen']['sentence_hin_Deva']\n\n# Convert them to lists\nenglish_sentences = list(english_sentences)\nhindi_sentences = list(hindi_sentences)\n\n# Verify the first few elements of each list\nprint(english_sentences[:5])\nprint(hindi_sentences[:5])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T04:20:27.260236Z","iopub.execute_input":"2024-07-31T04:20:27.260623Z","iopub.status.idle":"2024-07-31T04:20:27.276769Z","shell.execute_reply.started":"2024-07-31T04:20:27.260593Z","shell.execute_reply":"2024-07-31T04:20:27.275390Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['An appearance is a bunch of attributes related to the service person, like their shoes, clothes, tie, jewellery, hairstyle, make-up, watch, cosmetics, perfume, etc.', 'Ajanta, located in the Aurangabad District of Maharashtra has twenty-nine caitya and vihara caves decorated with sculptures and paintings from the first century B.C.E. to the fifth century C.E.', 'Body colour gets merged with the outer line, creating the effect of volume.', 'Ashoka started making extensive use of stone for sculptures and great monuments, whereas the previous tradition consisted of working with wood and clay.', 'Potatoes mixed in masalas, coated in besan batter and deep fried to perfection form this delicious and famous dish of Maharashtra.']\n['सेवा संबंधी लोगों के लिए भेष कई गुणों का संयोजन है, जैसे कि उनके जूते, कपड़े, टाई, आभूषण, केश शैली, मेक-अप, घड़ी, कॉस्मेटिक, इत्र, आदि।', 'महाराष्ट्र के औरंगाबाद जिले में स्थित अजंता में उन्तीस चैत्य और विहार गुफाएँ हैं जो पहली शताब्दी ई.पू. से ले कर पाँचवीं शताब्दी ईस्वी तक की मूर्तियों तथा चित्रकारियों से सुसज्जित हैं।', 'विस्तार का असर बनाते हुए, शरीर का रंग बाहरी रेखा में घुल-मिल जाता है।', 'अशोक ने व्यापक रूप से मूर्तियों और शानदार स्मारकों को बनाने के लिए पत्थर का प्रयोग करना शुरू किया, जबकि उससे पहले पारंपरिक रूप से लकड़ी और मिट्टी का प्रयोग किया जाता है।', 'महाराष्ट्र के इस स्वादिष्ट और प्रसिद्ध व्यंजन में आलुओं में मसाले को मिलाकर, बेसन के घोल की परत लगाकर, उसे अच्छी तरह से तल कर बनाया जाता है।']\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch, os\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-07-31T04:20:27.278499Z","iopub.execute_input":"2024-07-31T04:20:27.278942Z","iopub.status.idle":"2024-07-31T04:20:27.327550Z","shell.execute_reply.started":"2024-07-31T04:20:27.278904Z","shell.execute_reply":"2024-07-31T04:20:27.326293Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from transformers import MBart50Tokenizer,MBartForConditionalGeneration\nmodel_name ='/kaggle/input/hindi-1-val'\ntokenizer = MBart50Tokenizer.from_pretrained(model_name)\n# Load the model\nmodel = MBartForConditionalGeneration.from_pretrained(model_name)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-31T04:20:27.329004Z","iopub.execute_input":"2024-07-31T04:20:27.329431Z","iopub.status.idle":"2024-07-31T04:20:35.258453Z","shell.execute_reply.started":"2024-07-31T04:20:27.329399Z","shell.execute_reply":"2024-07-31T04:20:35.257487Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"MBartForConditionalGeneration(\n  (model): MBartModel(\n    (shared): Embedding(250054, 1024, padding_idx=1)\n    (encoder): MBartEncoder(\n      (embed_tokens): MBartScaledWordEmbedding(250054, 1024, padding_idx=1)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x MBartEncoderLayer(\n          (self_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): ReLU()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): MBartDecoder(\n      (embed_tokens): MBartScaledWordEmbedding(250054, 1024, padding_idx=1)\n      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-11): 12 x MBartDecoderLayer(\n          (self_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): ReLU()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MBartAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=250054, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"import sacrebleu\nfrom tqdm import tqdm\n\n# Function to generate translation for a given input text\ndef generate_translation(input_text):\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n    with torch.no_grad():\n        output_ids = model.generate(input_ids)\n    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return output_text\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T04:20:35.259874Z","iopub.execute_input":"2024-07-31T04:20:35.260254Z","iopub.status.idle":"2024-07-31T04:20:35.266535Z","shell.execute_reply.started":"2024-07-31T04:20:35.260221Z","shell.execute_reply":"2024-07-31T04:20:35.265625Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"translations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append([hindi_sentences[i]])\n\n# Calculate BLEU score\nbleu = sacrebleu.corpus_bleu(translations, references)\nprint(f\"BLEU score: {bleu.score}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-31T04:20:35.269648Z","iopub.execute_input":"2024-07-31T04:20:35.269939Z","iopub.status.idle":"2024-07-31T04:39:20.140760Z","shell.execute_reply.started":"2024-07-31T04:20:35.269915Z","shell.execute_reply":"2024-07-31T04:39:20.139562Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 1024/1024 [18:44<00:00,  1.10s/it]\n","output_type":"stream"},{"name":"stdout","text":"BLEU score: 26.069430553765887\n","output_type":"stream"}]},{"cell_type":"code","source":"translations = []\nreferences = []\nfor i in tqdm(range(0, len(english_sentences)), desc=\"Translating\"):\n    translations.append(generate_translation(english_sentences[i]))\n    references.append(hindi_sentences[i])  # For chrF++, references should be a flat list\n\n# Calculate chrF++ score\nchrf = sacrebleu.corpus_chrf(translations, references)\nprint(f\"chrF++ score: {chrf.score}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-31T04:39:20.142123Z","iopub.execute_input":"2024-07-31T04:39:20.142447Z","iopub.status.idle":"2024-07-31T04:58:01.728780Z","shell.execute_reply.started":"2024-07-31T04:39:20.142421Z","shell.execute_reply":"2024-07-31T04:58:01.727682Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Translating: 100%|██████████| 1024/1024 [18:38<00:00,  1.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"chrF++ score: 4.439746300211416\n","output_type":"stream"}]}]}